{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47781250",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import datasets, utils\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "from detection_tools.data.pascal_voc import CLASSES, tensorize_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3024965a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detection_tools.ssd_utils import VGG16FeatureExtractor\n",
    "feature_extractor = VGG16FeatureExtractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b08bd9a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG16FeatureExtractor(\n",
       "  (features_conv4_3): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "  )\n",
       "  (mod_pool5): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "  (remaining_features): Sequential(\n",
       "    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "  )\n",
       "  (fc6): Sequential(\n",
       "    (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (fc7): Sequential(\n",
       "    (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv8): Sequential(\n",
       "    (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv9): Sequential(\n",
       "    (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv10): Sequential(\n",
       "    (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv11): Sequential(\n",
       "    (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb8a3099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 38, 38])\n",
      "torch.Size([1, 1024, 19, 19])\n",
      "torch.Size([1, 512, 10, 10])\n",
      "torch.Size([1, 256, 5, 5])\n",
      "torch.Size([1, 256, 3, 3])\n",
      "torch.Size([1, 256, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "img = torch.randn(1, 3, 300, 300)\n",
    "features = feature_extractor(img)\n",
    "for feature in features:\n",
    "    print(feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b4671c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.Resize((300, 300)),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.48235, 0.45882, 0.40784], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "ds = datasets.VOCDetection(\n",
    "    root=\"../data/Pascal_VOC_Detection\",\n",
    "    transform=transform,\n",
    "    target_transform=tensorize_target\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c45bd2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    images = [batch[0] for batch in batch]\n",
    "    targets = [batch[1] for batch in batch]\n",
    "    images = torch.stack(images, dim=0)\n",
    "    return images, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08ad3bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = torch.utils.data.DataLoader(ds, batch_size=4, collate_fn=collate_fn, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62da2db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, targets = next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "331b7ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fmaps = feature_extractor(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77a4416f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512, 38, 38])\n",
      "torch.Size([4, 1024, 19, 19])\n",
      "torch.Size([4, 512, 10, 10])\n",
      "torch.Size([4, 256, 5, 5])\n",
      "torch.Size([4, 256, 3, 3])\n",
      "torch.Size([4, 256, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "for fmap in fmaps:\n",
    "    print(fmap.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5980b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detection_tools.ssd_utils import AnchorGenerator\n",
    "anchor_generator = AnchorGenerator(\n",
    "    aspect_ratios=[\n",
    "        [1.0, 2.0],\n",
    "        [1.0, 2.0, 3.0],\n",
    "        [1.0, 2.0, 3.0],\n",
    "        [1.0, 2.0, 3.0],\n",
    "        [1.0, 2.0],\n",
    "        [1.0, 2.0]\n",
    "    ]\n",
    ")\n",
    "anchors = anchor_generator.generate_anchors((300, 300), VGG16FeatureExtractor.MAP_SHAPES_300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fd7de09",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors = [anchors] * images.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a97c206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([-1, -1, -1,  ..., -1, -1, -1]), tensor([-1, -1, -1,  ..., -1, -1, -1]), tensor([-1, -1, -1,  ..., -1, -1, -1]), tensor([-1, -1, -1,  ...,  0,  0, -1])]\n"
     ]
    }
   ],
   "source": [
    "from detection_tools.ssd_utils import Matcher, SSDHead, SSDLoss\n",
    "matcher = Matcher(iou_threshold=0.5)\n",
    "matches = []\n",
    "for target, anchor in zip(targets, anchors):\n",
    "    match = matcher(target[\"boxes\"], anchor)\n",
    "    matches.append(match)\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "819bb30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "296\n",
      "38\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "for match in matches:\n",
    "    print(match[match >= 0].numel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10b64b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detection_tools.ssd_utils import OffsetHandler\n",
    "o_handler = OffsetHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7fb3335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 6, 6, 6, 4, 4]\n"
     ]
    }
   ],
   "source": [
    "num_anchors_per_location_per_map = [len(wh_pair) for wh_pair in anchor_generator.height_width_pairs]\n",
    "print(num_anchors_per_location_per_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5387935",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = [512, 1024, 512, 256, 256, 256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0944754",
   "metadata": {},
   "outputs": [],
   "source": [
    "head = SSDHead(num_classes=len(CLASSES)+1, num_anchors=num_anchors_per_location_per_map, channels=in_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "757ff559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8732, 4])\n",
      "torch.Size([4, 8732, 21])\n"
     ]
    }
   ],
   "source": [
    "head_outputs = head(fmaps)\n",
    "print(head_outputs[\"offsets\"].shape)\n",
    "print(head_outputs[\"cls_logits\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19c38030",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = SSDLoss(neg_pos_ratio=3, o_handler=o_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6ba3840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reg_loss': tensor(0.8864, grad_fn=<DivBackward0>), 'cls_loss': tensor(20.4386, grad_fn=<DivBackward0>)}\n"
     ]
    }
   ],
   "source": [
    "loss_vals = loss(targets, head_outputs, anchors, matches, raw=True)\n",
    "print(loss_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "68a215d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detection_tools.ssd_utils import SSDPredictor\n",
    "predictor = SSDPredictor(o_handler=o_handler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2e3df27",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predictor(head_outputs, anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ca9f13c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8074, 0.8046, 0.7584, 0.7526, 0.7494, 0.7437, 0.7432, 0.7298, 0.7150,\n",
       "        0.7113, 0.7089, 0.7060, 0.6956, 0.6882, 0.6851, 0.6810, 0.6775, 0.6764,\n",
       "        0.6753, 0.6739, 0.6708, 0.6676, 0.6650, 0.6561, 0.6526, 0.6515, 0.6513,\n",
       "        0.6463, 0.6438, 0.6397, 0.6385, 0.6381, 0.6366, 0.6334, 0.6309, 0.6308,\n",
       "        0.6263, 0.6240, 0.6238, 0.6197, 0.6171, 0.6164, 0.6136, 0.6088, 0.6070,\n",
       "        0.6064, 0.6057, 0.6051, 0.6037, 0.6035, 0.5950, 0.5940, 0.5933, 0.5911,\n",
       "        0.5903, 0.5881, 0.5874, 0.5861, 0.5855, 0.5831, 0.5828, 0.5817, 0.5813,\n",
       "        0.5809, 0.5755, 0.5731, 0.5724, 0.5723, 0.5708, 0.5707, 0.5672, 0.5661,\n",
       "        0.5652, 0.5638, 0.5615, 0.5605, 0.5604, 0.5602, 0.5601, 0.5585, 0.5582,\n",
       "        0.5548, 0.5520, 0.5478, 0.5445, 0.5424, 0.5423, 0.5416, 0.5390, 0.5381,\n",
       "        0.5380, 0.5379, 0.5367, 0.5352, 0.5347, 0.5335, 0.5321, 0.5287, 0.5285,\n",
       "        0.5279, 0.5244, 0.5238, 0.5224, 0.5224, 0.5215, 0.5214, 0.5200, 0.5200,\n",
       "        0.5198, 0.5189, 0.5187, 0.5180, 0.5172, 0.5171, 0.5164, 0.5145, 0.5142,\n",
       "        0.5133, 0.5132, 0.5129, 0.5112, 0.5111, 0.5110, 0.5109, 0.5108, 0.5103,\n",
       "        0.5099, 0.5098, 0.5070, 0.5067, 0.5065, 0.5049, 0.5049, 0.5037, 0.5034,\n",
       "        0.5030, 0.5023, 0.5017, 0.5015, 0.5007, 0.4992, 0.4979, 0.4978, 0.4977,\n",
       "        0.4975, 0.4974, 0.4973, 0.4969, 0.4964, 0.4960, 0.4958, 0.4947, 0.4941,\n",
       "        0.4938, 0.4936, 0.4931, 0.4931, 0.4929, 0.4919, 0.4916, 0.4910, 0.4906,\n",
       "        0.4901, 0.4898, 0.4893, 0.4880, 0.4879, 0.4878, 0.4878, 0.4877, 0.4877,\n",
       "        0.4852, 0.4846, 0.4830, 0.4829, 0.4824, 0.4816, 0.4810, 0.4808, 0.4801,\n",
       "        0.4795, 0.4787, 0.4784, 0.4782, 0.4768, 0.4765, 0.4763, 0.4762, 0.4758,\n",
       "        0.4754, 0.4750, 0.4749, 0.4745, 0.4742, 0.4731, 0.4731, 0.4723, 0.4722,\n",
       "        0.4721, 0.4720], grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0][\"scores\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env-pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
